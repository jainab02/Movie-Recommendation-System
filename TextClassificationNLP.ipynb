{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOEfp5c/RoYJ2JjGMn/cRX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jainab02/Text-Classification-Model/blob/main/TextClassificationNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification using NLP"
      ],
      "metadata": {
        "id": "LpHJchxG9WwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Points:\n",
        "\n",
        "*   The dataset we are using is the IMDB dataset which is prebuilt in keras for faster execution and provides us the movie data along with genres.\n",
        "*   Here we are usign text classification to to classify the movie in their respective genres.\n",
        "\n",
        "\n",
        "*   For simple implementation we are using 10,0000 records.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KWVXs6Ta9ZBB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OBoEnpANlBbK"
      },
      "outputs": [],
      "source": [
        "# importing the necessary libraries needed\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading and defining the dataset\n",
        "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=10000)\n",
        "dt = np.concatenate((train_data, test_data), axis=0)\n",
        "tar = np.concatenate((train_target, test_target), axis=0)"
      ],
      "metadata": {
        "id": "yU5Dap8E6V7A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using Convert() function to convert the words into vectors for processing\n",
        "def convert(sequences, dimension = 10000):\n",
        " results = np.zeros((len(sequences), dimension))\n",
        " for i, sequence in enumerate(sequences):\n",
        "  results[i, sequence] = 1\n",
        " return results"
      ],
      "metadata": {
        "id": "jiV-DBuc6YqO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide our dataset into train and test sets\n",
        "dt = convert(dt)\n",
        "tar = np.array(tar).astype(\"float32\")\n",
        "test_x = dt[:9000]\n",
        "test_y = tar[:9000]\n",
        "train_x = dt[9000:]\n",
        "train_y = tar[9000:]\n",
        "model = models.Sequential()"
      ],
      "metadata": {
        "id": "r7ibU2sS6bzt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input - Layer\n",
        "model.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))"
      ],
      "metadata": {
        "id": "HnJrwU2u-1dY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden - Layers\n",
        "model.add(layers.Dropout(0.4, noise_shape=None, seed=None))\n",
        "model.add(layers.Dense(50, activation = \"relu\"))\n",
        "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
        "model.add(layers.Dense(50, activation = \"relu\"))"
      ],
      "metadata": {
        "id": "vXR6-i9u-44I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output- Layer\n",
        "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lJBZ3_-6k67",
        "outputId": "3e5d4343-a6af-4383-d5c4-03d6ea85c4f9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 50)                500050    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 505,201\n",
            "Trainable params: 505,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model.compile(\n",
        " optimizer = \"adam\",\n",
        " loss = \"binary_crossentropy\",\n",
        " metrics = [\"acc\"]\n",
        ")"
      ],
      "metadata": {
        "id": "4N3Kcl3Z6sGL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resulting and printing the accuracy\n",
        "results = model.fit(\n",
        " train_x, train_y,\n",
        " epochs= 2,\n",
        " batch_size = 500,\n",
        " validation_data = (test_x, test_y)\n",
        ")\n",
        "print(\"Testing Accuracy for text classification of IMDB dataset :\", np.mean(results.history[\"val_acc\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFlXI4TJ6xYk",
        "outputId": "0b218dce-1d91-4419-f9c8-0e7b886b9af3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "82/82 [==============================] - 7s 69ms/step - loss: 0.4092 - acc: 0.8155 - val_loss: 0.2587 - val_acc: 0.8948\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 6s 67ms/step - loss: 0.2262 - acc: 0.9120 - val_loss: 0.2586 - val_acc: 0.8963\n",
            "Testing Accuracy for text classification of IMDB dataset : 0.8955555558204651\n"
          ]
        }
      ]
    }
  ]
}